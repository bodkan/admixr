---
title: "Fitting qpAdm models with a 'rotation method'"
author: "Martin Petr"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

qpAdm model fitting is a very complex topic which relies on a deep
knowledge of the concepts behind $f$-statistics introduced by Nick
Patterson and colleagues [in
2012](https://www.genetics.org/content/192/3/1065). In our
[tutorial](https://bodkan.net/admixr/articles/tutorial.html#qpwave-and-qpadm-1)
we have looked at the very basic overview of the qpWave/qpAdm-related
functionality implemented in _admixr_, without going beyond
description of functions and function arguments. I have also stressed
how important it is to learn _how_ does qpAdm works, linking to
several important references.

Recently, an exciting new preprint was published by Harney _et al._,
[Assessing the Performance of qpAdm: A Statistical Tool for Studying
Population
Admixture](https://www.biorxiv.org/content/10.1101/2020.04.09.032664v1). Before
we go any further, I encourage everyone to read it and also read the
superb tutorial/guide available in a [supplementary
pdf](https://www.biorxiv.org/content/10.1101/2020.04.09.032664v1.supplementary-material)
on bioRxiv. There really isn't a better source at the moment on how to
run and interpret qpAdm analyses and about the pitfals that one needs
to be aware of.

Please, only attempt to run qpAdm if you have familiarized yoursef
with all of the above-mentioned resources. I have had many people ask
questions via email (not only about qpAdm but also other topics) to
which the only sensible answer was - "you have to read the papers and
understand the statistics".

## _qpAdm_ "rotation scheme"

If you have ever worked with _qpAdm_, you are well aware of the
intricacies of finding the most suitable set of models that can
explain the data. Among other things, we have need to make a decision
about the number of admixture sources we want to estimate ancestry
proportions for, which populations are the most appropriate surrogates
for those source populations because only rarely we have sampled them
directly. Furthermore, we need to carefully choose a number of so
called 'outgroup' populations (also called 'references' or 'right'
populations, depending whom you ask). This is all, of course, in
addition to other technical decisions we need to make in terms of
preparing our dataset.

The preprint by [Harney _et
al._](https://www.biorxiv.org/content/10.1101/2020.04.09.032664v1)
described an interesting idea to find a set of the most appropriate
models (sets of source and outgroup populations) - the so called
"rotating" population, already successfully used in the past (see
references in the preprint).

Briefly, this strategy involves defining a set of "candidate"
populations, from which we iteratively sample a defined number of
"sources" (most commonly two or three) for our "target" population of
interest. We then take as "outgroups" all candidate populations except
for these sources. Doing so, we iteratively fit qpAdm models for each
combination of target, sources and outgroups, extracting $p$-values
and other statistics of interest. After finishing the exhaustive
exploration of source-outgroup combinations, we examine all fitted
models, selecting those that seem most appropriate.

## Implementation in _admixr_

In _admixr_, I have implemented a function `qpAdm_rotation()` which
does exactly what I described in the previous paragraph with one
additional feature. Given the sensitivity of _qpAdm_ to large numbers
of potential outgroups (references), we also explore, for each
combination of sources and outgroups, also models with all possible
_subsets_ of outgroups. This is to allow finding models which are as
small as possible, and also to determine which outgroups are
potentially redundant.

In other words, if we have a target _T_ and a set of candidates
(potential sources and outgroups) _C_ = {a, b, c, d, e, f}. Then, if
we imagine an iteration of the rotation scheme in which we fix sources
_S_ = {a, b}, we have remaining candidates _C - S_ = {c, d, e, f}. The
basic implementation of the rotation procedure would simly take _C -
S_ as the set of outgroups and fitted a single model:

- model #1: _T_, _S_ = {a, b} and outgroups = {c, d, e, f}

In _admixr_, we would, in this situation, evaluate the following
models:

- model #2: _T_, _S_ = {a, b} and outgroups = {c, d, e}
- model #3: _T_, _S_ = {a, b} and outgroups = {c, d, f}
- model #4: _T_, _S_ = {a, b} and outgroups = {c, e, f}
- model #5: _T_, _S_ = {a, b} and outgroups = {d, e, f}.

This makes it possible to find the _smallest_ model (in terms of
outgroup size) that can explain our data.

## Concrete example

### Performing exhaustive search by rotating sources/outgroups

As an example, let's revisit our boring example of estimating the
level of Neandertal ancestry in a French person. We use it (and not
some other more interesting example from a vast human population
history) because:

1. It's probably the simplest possible $f$-statistics-related analysis
   one could do.
2. It gives us a clear expectation of what the "truth" is.
3. It gives us a clear expectation of what models we should
   _definitely_ reject.
4. It's the only thing I know how to do.

Let's first download a small example data set:

```{r}
library(admixr)

snps <- eigenstrat(download_data())
```

These are the individuals for which we have genotype data:

```{r}
read_ind(snps)
```

The `qpAdm_rotation()` function is very simple. It accepts:

- the name of the target population,
- the list of candidate populations,
- a logical parameter `minimize` determining whether to perform the
  "minimization" of the outgroup size described in the previous
  section,
- the number of sources of ancestry
- the number of CPU cores to use for an analysis (be careful with this
  options as many ADMIXTOOLS analyses run in paralle often consume _a
  lot_ of memory!),
- parameter `fulloutput` specifying whether we want to have all the
  "ranks" and "subsets/patterns" statistics (see the tutorial for more
  information) or if we just want the proportions of ancestry and
  significance values for individual models (this is the default).

Let's say we are interested in finding the proportions of archaic
human ancestry in a French individual, and also in seeing what sorts
of possible models we could find that match archaic introgression:

```{r}
models <- qpAdm_rotation(
    data = snps,
    target = "French",
    candidates = c("Dinka", "Mbuti", "Yoruba", "Vindija", "Altai", "Denisova", "Chimp"),
    minimize = TRUE,
    nsources = 2,
    ncores = 30,
    fulloutput = TRUE
)
```

On my computing cluster this takes only a couple of minutes but note
that I'm utilizing 30 CPU cores in parallel. On your computer it might
take a bit more time. If it takes _too_ much time, you might want to
restrict the set of potential candidates or turn of the minimization
option.

Here is what the full output looks like:

```{r}
models
```

We can see that we got a list with three components, as we would
expect from any other `qpAdm()` run (see the manual page and the
tutorial for description of all three elements and their meaning). The
first column is named `model` - this is just a short identifier of
each individual "rotation" run. It's values don't have any particular
meaning, but are useful for later filtering and examination.

Let's ignore the `$ranks` and `$subsets` elements, these are not that
useful in the first step of model selection. We will focus only on the
first element, `$proportions`.


### Examining and filtering fitted models

The output data.frame contains information about *all* objects,
regardless of their plausibility. We can see that by examining the
distributions of p-values (column `pvalue`) and admixture proportions
(columns `prop1` and `prop2`) of each evaluated model.

Notice two things:

- Many models have inferred admixture proportions _way_ outside the
  [0, 1] interval - those are clearly nonsensical.
- Many models have very low p-values - knowing how qpAdm internally
  operates, you will know this means these are incompatible with the
  data and can be rejected.

```{r}
library(tidyverse)

select(models$proportions, model, pvalue, prop1, prop2) %>%
    gather(parameter, value, -model) %>%
    ggplot(aes(parameter, value)) +
    geom_jitter() +
    facet_wrap(~ parameter, scales = "free_y")
```

The _admixr_ package contains a simple function `qpAdm_filter()` which
accepts the object produced by the `qpAdm_rotation()` function (either
the `fulloutput` version or the simple) and removes models with any
proportion outside of the [0, 1] range and also models with p-values
lower than a specified cutoff (0.05 by default):

```{r}
fits <- qpAdm_filter(models)
```

As an aside, note that you can use the function `loginfo()` to examine
the complete log output of any model by specifying the model number
(this is why each row has the model identifier). Like this (output
omitted for brevity):

```{r, eval = FALSE}
loginfo(fits, "m81")
```

We can verify the filtering worked by examining the filtered set of
models. Again, note that the p-values are now nicely distributed
across the range of "insigificance" (i.e., "non-rejection") range of
[0.05, 1.0]. And, also (remember that we tried to find a set of
sources-outgroups combinations that model archaic ancestry in a French
individual?) we see two nice clusters of ancestry proportions - one
very small (which what we will see is a Neandertal component) and one
large ("modern human" component, non-Neandertal ancestry):

```{r}
select(fits$proportions, model, pvalue, prop1, prop2) %>%
    gather(parameter, value, -model) %>%
    ggplot(aes(parameter, value)) +
    geom_jitter() +
    facet_wrap(~ parameter) +
    coord_cartesian(y = c(0, 1))
```

Let's now subset only to the proportions table which is most relevant
at this stage anyway. We will also ignore a couple of columns for
brevity (*note* that we are also ignoring p-values because we *cannot*
used those for model selection, they are *not* meaningful at this
stage) and order the models based on the size of the outgroup set.

```{r}
props <- fits$proportions %>%
    arrange(noutgroups) %>%
    select(-c(target, noutgroups, stderr1, stderr2, nsnps_used, nsnps_target))

print(props, n = Inf)
```

Also, before you run away terrified by the huge number of "compatible"
models, please note that we have _deliberately_ added too many
candidate populations and so you might reasonably expect many of the
evaluated models are not really optimal.

Case in point: notice that there are many models in which the
chimpanzee was fitted as a source of ancestry! Interestingly, qpAdm
used it to "sucessfully" infer archaic human ancestry (where we define
"successful model" by inferring ancestry proportions between 0 and 1,
and a high p-value). This is because Neandertal ancestry could be
considered an "ancestral component" of a modern human genome:

```{r}
filter(props, source1 == "Chimp" | source2 == "Chimp")
```

## Conclusions

At this stage of analysis you would be on your own. You would have to
decide which models are more reasonably and why, possibly based on
prior knowledge or additional statistics (such as the details
information reported in the full log output information). This is
because qpAdm on some level is as much art as it is science and
interpreting the results and finding the most appropriate models can
be quite a challenge.
